{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(r\"C:\\Users\\thanh\\Downloads\\jobs.merged_collections_1.json\",'r',encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasketch\n",
      "  Obtaining dependency information for datasketch from https://files.pythonhosted.org/packages/81/71/fb0c28eff49fc0d725782f6dcf4ba2f71c52b6e6e9575179df3802b19d90/datasketch-1.6.4-py3-none-any.whl.metadata\n",
      "  Downloading datasketch-1.6.4-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy>=1.11 in d:\\anaconda3\\envs\\thanhnx\\lib\\site-packages (from datasketch) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in d:\\anaconda3\\envs\\thanhnx\\lib\\site-packages (from datasketch) (1.11.3)\n",
      "Downloading datasketch-1.6.4-py3-none-any.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.3 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/88.3 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 81.9/88.3 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 88.3/88.3 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: datasketch\n",
      "Successfully installed datasketch-1.6.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate neighbours with Jaccard similarity > 0.5 ['m2', 'm3']\n"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "set1 = set(['minhash', 'is', 'a', 'probabilistic', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'datasets'])\n",
    "set2 = set(['minhash', 'is', 'a', 'probability', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'documents'])\n",
    "set3 = set(['minhash', 'is', 'probability', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'documents'])\n",
    "\n",
    "m1 = MinHash(num_perm=128)\n",
    "m2 = MinHash(num_perm=128)\n",
    "m3 = MinHash(num_perm=128)\n",
    "for d in set1:\n",
    "    m1.update(d.encode('utf8'))\n",
    "for d in set2:\n",
    "    m2.update(d.encode('utf8'))\n",
    "for d in set3:\n",
    "    m3.update(d.encode('utf8'))\n",
    "\n",
    "# Create LSH index\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=128)\n",
    "lsh.insert(\"m2\", m2)\n",
    "lsh.insert(\"m3\", m3)\n",
    "result = lsh.query(m1)\n",
    "print(\"Approximate neighbours with Jaccard similarity > 0.5\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for x in data:\n",
    "    text = ''\n",
    "    for key in list(x.keys()):\n",
    "        if type(x[key]) == str:\n",
    "            text += x[key]\n",
    "        elif type(x[key]) == list:\n",
    "            text += ' ' + ' '.join(x[key])\n",
    "    texts.append(text)\n",
    "texts = [set(i.split()) for i in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate using minhash + LSH if jaccard similarity > 0.8\n",
    "minhashes = {}\n",
    "lsh = MinHashLSH(threshold=0.8, num_perm=128)\n",
    "for i, req in enumerate(texts):\n",
    "    m = MinHash(num_perm=128)\n",
    "    for d in req:\n",
    "        m.update(d.encode('utf8'))\n",
    "    minhashes[i] = m\n",
    "    lsh.insert(i, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicates\n",
    "duplicates = []\n",
    "for i, req in enumerate(texts):\n",
    "    result = lsh.query(minhashes[i])\n",
    "    if len(result) > 1:\n",
    "        duplicates.append(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in duplicates:\n",
    "    if len(x) > 1:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': {'$oid': '657882c681ab5b1bd0570b3e'},\n",
       " 'keyword': 'back-end developer',\n",
       " 'job_name': 'ANDROID DEVELOPER (LẬP TRÌNH VIÊN)',\n",
       " 'requirements': [],\n",
       " 'salary': ['2 times/year', '34000K - 34000K VND một tháng'],\n",
       " 'offer': ['Chăm Sóc Sức Khỏe, Chế độ bảo hiểm, Thưởng doanh thu, Hỗ trợ Laptop'],\n",
       " 'location': 'Ho Chi Minh',\n",
       " 'company': 'Việc Ơi It Client',\n",
       " 'from': 'indeed'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "for i in duplicates:\n",
    "    for j in i[1:]:\n",
    "        data[j]['requirements'] = []\n",
    "        data[j]['from'] = 'duplicate'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11967"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [i for i in data if i['from'] != 'duplicate']\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14509"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json\n",
    "with open('./data_deduplicated.json','w',encoding='utf-8') as f:\n",
    "    json.dump(new_data,f,ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thanhnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
